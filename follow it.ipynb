{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":29962,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set Parameters\nim_width = 256\nim_height = 256\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:53:55.432954Z","iopub.execute_input":"2023-11-20T16:53:55.433315Z","iopub.status.idle":"2023-11-20T16:53:55.437262Z","shell.execute_reply.started":"2023-11-20T16:53:55.433276Z","shell.execute_reply":"2023-11-20T16:53:55.436614Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load image's path and mask's path**","metadata":{"editable":false}},{"cell_type":"code","source":"train_files = []\nmask_files = glob('../input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\n\nfor i in mask_files:\n    train_files.append(i.replace('_mask',''))\n\nprint(train_files[:10])\nprint(mask_files[:10])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:53:55.438767Z","iopub.execute_input":"2023-11-20T16:53:55.439125Z","iopub.status.idle":"2023-11-20T16:53:59.238564Z","shell.execute_reply.started":"2023-11-20T16:53:55.439089Z","shell.execute_reply":"2023-11-20T16:53:59.237668Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization**","metadata":{"editable":false}},{"cell_type":"code","source":"#Lets plot some samples\nrows,cols=3,3\nfig=plt.figure(figsize=(10,10))\nfor i in range(1,rows*cols+1):\n    fig.add_subplot(rows,cols,i)\n    img_path=train_files[i]\n    msk_path=mask_files[i]\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    msk=cv2.imread(msk_path)\n    plt.imshow(img)\n    plt.imshow(msk,alpha=0.4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:53:59.239794Z","iopub.execute_input":"2023-11-20T16:53:59.240073Z","iopub.status.idle":"2023-11-20T16:54:00.772059Z","shell.execute_reply.started":"2023-11-20T16:53:59.240045Z","shell.execute_reply":"2023-11-20T16:54:00.771337Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create data frame and split data on train set, validation set and test set**","metadata":{"editable":false}},{"cell_type":"code","source":"df = pd.DataFrame(data={\"filename\": train_files, 'mask' : mask_files})\ndf_train, df_test = train_test_split(df,test_size = 0.1)\ndf_train, df_val = train_test_split(df_train,test_size = 0.2)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:00.774909Z","iopub.execute_input":"2023-11-20T16:54:00.775217Z","iopub.status.idle":"2023-11-20T16:54:00.791376Z","shell.execute_reply.started":"2023-11-20T16:54:00.775182Z","shell.execute_reply":"2023-11-20T16:54:00.790518Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data genertator, data augmentation and adjust data**","metadata":{"editable":false}},{"cell_type":"code","source":"# From: https://github.com/zhixuhao/unet/blob/master/data.py\ndef train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:00.792811Z","iopub.execute_input":"2023-11-20T16:54:00.793143Z","iopub.status.idle":"2023-11-20T16:54:00.806582Z","shell.execute_reply.started":"2023-11-20T16:54:00.793108Z","shell.execute_reply":"2023-11-20T16:54:00.805814Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Define loss function and metrics**","metadata":{"editable":false}},{"cell_type":"code","source":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:00.80777Z","iopub.execute_input":"2023-11-20T16:54:00.808078Z","iopub.status.idle":"2023-11-20T16:54:00.819003Z","shell.execute_reply.started":"2023-11-20T16:54:00.80805Z","shell.execute_reply":"2023-11-20T16:54:00.818268Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Define Unet**","metadata":{"editable":false}},{"cell_type":"code","source":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(32, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(64, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(64, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(128, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(128, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(256, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(256, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(512, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(512, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n    pool5 = MaxPooling2D(pool_size=(2, 2))(bn5)\n\n    conv6 = Conv2D(1024, (3, 3), padding='same')(pool5)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(1024, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn6), conv5], axis=3)\n    conv7 = Conv2D(512, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(512, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn7), conv4], axis=3)\n    conv8 = Conv2D(256, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(256, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn8), conv3], axis=3)\n    conv9 = Conv2D(128, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(128, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    up10 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn9), conv2], axis=3)\n    conv10 = Conv2D(64, (3, 3), padding='same')(up10)\n    bn10 = Activation('relu')(conv10)\n    conv10 = Conv2D(64, (3, 3), padding='same')(bn10)\n    bn10 = BatchNormalization(axis=3)(conv10)\n    bn10 = Activation('relu')(bn10)\n    \n    up11 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(bn10), conv1], axis=3)\n    conv11 = Conv2D(64, (3, 3), padding='same')(up11)\n    bn11 = Activation('relu')(conv11)\n    conv11 = Conv2D(64, (3, 3), padding='same')(bn11)\n    bn11 = BatchNormalization(axis=3)(conv11)\n    bn11 = Activation('relu')(bn11)\n\n    conv12 = Conv2D(1, (1, 1), activation='sigmoid')(bn11)\n\n    return Model(inputs=[inputs], outputs=[conv12])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:00.820257Z","iopub.execute_input":"2023-11-20T16:54:00.820608Z","iopub.status.idle":"2023-11-20T16:54:00.860335Z","shell.execute_reply.started":"2023-11-20T16:54:00.820573Z","shell.execute_reply":"2023-11-20T16:54:00.859465Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:00.861825Z","iopub.execute_input":"2023-11-20T16:54:00.862097Z","iopub.status.idle":"2023-11-20T16:54:04.033901Z","shell.execute_reply.started":"2023-11-20T16:54:00.862064Z","shell.execute_reply":"2023-11-20T16:54:04.03294Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{"editable":false}},{"cell_type":"code","source":"EPOCHS = 50\nBATCH_SIZE = 32\nlearning_rate = 1e-4","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:04.035045Z","iopub.execute_input":"2023-11-20T16:54:04.035359Z","iopub.status.idle":"2023-11-20T16:54:04.039791Z","shell.execute_reply.started":"2023-11-20T16:54:04.035329Z","shell.execute_reply":"2023-11-20T16:54:04.038919Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=(im_height, im_width))\n    \ntest_gener = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=(im_height, im_width))\n    \nmodel = unet(input_size=(im_height, im_width, 3))\n\n\n\ndecay_rate = learning_rate / EPOCHS\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gener,\n                    validation_steps=len(df_val) / BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:54:04.041025Z","iopub.execute_input":"2023-11-20T16:54:04.041387Z","iopub.status.idle":"2023-11-20T17:45:02.704511Z","shell.execute_reply.started":"2023-11-20T16:54:04.041356Z","shell.execute_reply":"2023-11-20T17:45:02.703514Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:45:02.706043Z","iopub.execute_input":"2023-11-20T17:45:02.706325Z","iopub.status.idle":"2023-11-20T17:45:03.000365Z","shell.execute_reply.started":"2023-11-20T17:45:02.706296Z","shell.execute_reply":"2023-11-20T17:45:02.999481Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('unet_brain_mri_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:45:03.001761Z","iopub.execute_input":"2023-11-20T17:45:03.002136Z","iopub.status.idle":"2023-11-20T17:45:04.605463Z","shell.execute_reply.started":"2023-11-20T17:45:03.002088Z","shell.execute_reply":"2023-11-20T17:45:04.604612Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=(im_height, im_width))\nresults = model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\nprint(\"Test lost: \",results[0])\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:45:04.606948Z","iopub.execute_input":"2023-11-20T17:45:04.607244Z","iopub.status.idle":"2023-11-20T17:45:13.852061Z","shell.execute_reply.started":"2023-11-20T17:45:04.607217Z","shell.execute_reply":"2023-11-20T17:45:13.851253Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:45:13.85342Z","iopub.execute_input":"2023-11-20T17:45:13.853729Z","iopub.status.idle":"2023-11-20T17:45:29.306471Z","shell.execute_reply.started":"2023-11-20T17:45:13.853698Z","shell.execute_reply":"2023-11-20T17:45:29.305433Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}